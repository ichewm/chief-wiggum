#!/usr/bin/env bash
# Chief Wiggum - Worker orchestration runner
set -euo pipefail

WIGGUM_HOME="${WIGGUM_HOME:-$HOME/.claude/chief-wiggum}"
PROJECT_DIR="$(pwd)"
RALPH_DIR="${RALPH_DIR:-$PROJECT_DIR/.ralph}"

# Source shared libraries
source "$WIGGUM_HOME/lib/core/exit-codes.sh"
source "$WIGGUM_HOME/lib/core/defaults.sh"
source "$WIGGUM_HOME/lib/tasks/task-parser.sh"
source "$WIGGUM_HOME/lib/tasks/plan-parser.sh"
source "$WIGGUM_HOME/lib/tasks/conflict-detection.sh"
source "$WIGGUM_HOME/lib/core/logger.sh"
source "$WIGGUM_HOME/lib/core/file-lock.sh"
source "$WIGGUM_HOME/lib/utils/audit-logger.sh"
source "$WIGGUM_HOME/lib/utils/activity-log.sh"
source "$WIGGUM_HOME/lib/worker/worker-lifecycle.sh"
source "$WIGGUM_HOME/lib/worker/git-state.sh"
source "$WIGGUM_HOME/lib/claude/usage-tracker.sh"
source "$WIGGUM_HOME/lib/git/worktree-helpers.sh"

# Default configuration
MAX_WORKERS=4
MAX_ITERATIONS=20       # Max outer loop iterations per worker
MAX_TURNS=50           # Max turns per Claude session
SYNC_INTERVAL=36       # Run sync every N iterations (3 minutes at 5s sleep)
AGENT_TYPE="system.task-worker"  # Default agent type (can be overridden with 'plan' mode)
PID_WAIT_TIMEOUT=300   # Deciseconds to wait for agent.pid (30 seconds)
FORCE_LOCK=false       # --force flag state for lock override
MAX_SKIP_RETRIES=3     # Kanban update failures before permanent skip
FIX_WORKER_TIMEOUT=1800  # Fix worker max runtime (seconds)
FIX_WORKER_LIMIT=2     # Max concurrent fix workers
AGING_FACTOR=7         # Scheduling events per priority level promotion
SIBLING_WIP_PENALTY=20000  # Fixed-point penalty when sibling is WIP (20000 = 2.0)
PLAN_BONUS=15000           # Fixed-point bonus for tasks with plans (15000 = 1.5)
DEP_BONUS_PER_TASK=7000    # Fixed-point bonus per task blocked (7000 = 0.7)

show_help() {
    cat << EOF
wiggum run - Orchestrate workers for incomplete tasks

Usage: wiggum run [mode] [options]

Modes:
  (default)            Use system.task-worker agent (standard execution)
  plan                 Use system.task-worker agent with plan mode enabled (creates
                       implementation plan before execution)

Options:
  --max-workers N      Maximum concurrent workers (default: 4)
  --max-iters N        Maximum iterations per worker (default: 20)
  --max-turns N        Maximum turns per Claude session (default: 50)
  --force              Override stale orchestrator lock
  -h, --help          Show this help message

Examples:
  wiggum run                              # Start orchestration with defaults
  wiggum run plan                         # Use planning mode for all workers
  wiggum run --max-workers 8              # Start with max 8 workers
  wiggum run plan --max-workers 2         # Planning mode with 2 workers

Behavior:
  - Chief assigns pending tasks [ ] to workers based on dependency graph
  - Tasks are scheduled by priority: HIGH > MEDIUM > LOW
  - Tasks with unsatisfied dependencies are blocked until deps complete
  - Tasks are marked in-progress [=] when assigned
  - Workers mark tasks pending approval [P] when PR is created
  - Periodic sync updates [P] -> [x] when PRs are merged
  - Chief waits until all tasks are complete [x]
  - New workers spawn as old ones finish (up to max)
  - Circular dependencies are detected and reported at startup

EOF
}

# Spawn a worker for a task using wiggum-start
# Sets: SPAWNED_WORKER_ID, SPAWNED_WORKER_PID (for caller to use)
spawn_worker() {
    local task_id="$1"

    # Use wiggum-start to start the worker, capturing exit code
    local start_output
    local start_exit_code
    start_output=$("$WIGGUM_HOME/bin/wiggum-start" "$task_id" \
        --max-iters "$MAX_ITERATIONS" --max-turns "$MAX_TURNS" \
        --agent-type "$AGENT_TYPE" 2>&1) || start_exit_code=$?
    start_exit_code=${start_exit_code:-0}

    # Handle specific exit codes
    if [ "$start_exit_code" -eq "$EXIT_WORKER_ALREADY_EXISTS" ]; then
        # Worker directory exists from previous run
        # Exclude plan workers (worker-TASK-xxx-plan-*) - those are read-only planning sessions
        local existing_dir
        existing_dir=$(find_any_worker_by_task_id "$RALPH_DIR" "$task_id" | grep -v -- '-plan-' || true)
        if [ -n "$existing_dir" ]; then
            # Check if the worker process is still running
            local stale_pid
            stale_pid=$(cat "$existing_dir/agent.pid" 2>/dev/null || true)
            if [ -n "$stale_pid" ] && kill -0 "$stale_pid" 2>/dev/null; then
                # TRAP: Process is still running, refuse to spawn duplicate
                log_error "Worker for $task_id is still running (PID: $stale_pid)"
                log_error "Use 'wiggum stop $task_id' or 'wiggum kill $task_id' first"
                return 1
            fi
            # Process not running, safe to clean up stale directory
            log "Cleaning up stale worker directory for $task_id: $(basename "$existing_dir")"
            rm -rf "$existing_dir"
            # Retry spawning - reset exit code first
            start_exit_code=0
            start_output=$("$WIGGUM_HOME/bin/wiggum-start" "$task_id" \
                --max-iters "$MAX_ITERATIONS" --max-turns "$MAX_TURNS" \
                --agent-type "$AGENT_TYPE" 2>&1) || start_exit_code=$?
        fi
    fi

    # Check if spawn succeeded
    if [ "$start_exit_code" -ne 0 ]; then
        log_error "wiggum start failed (exit $start_exit_code): $start_output"
        return 1
    fi

    # Find the worker directory that was just created (using shared library)
    local worker_dir
    worker_dir=$(find_worker_by_task_id "$RALPH_DIR" "$task_id")

    if [ -z "$worker_dir" ]; then
        log_error "Failed to find worker directory for $task_id"
        return 1
    fi

    SPAWNED_WORKER_ID=$(basename "$worker_dir")

    # Wait for agent.pid to appear (using shared library)
    if ! wait_for_worker_pid "$worker_dir" "$PID_WAIT_TIMEOUT"; then
        log_error "Agent PID file not created for $task_id"
        return 1
    fi

    SPAWNED_WORKER_PID=$(cat "$worker_dir/agent.pid")
    activity_log "worker.spawned" "$SPAWNED_WORKER_ID" "$task_id" "pid=$SPAWNED_WORKER_PID"
}

# Run periodic sync to update PR statuses and detect new comments
run_periodic_sync() {
    # Call wiggum review sync and capture output
    local sync_output sync_exit=0
    sync_output=$("$WIGGUM_HOME/bin/wiggum-review" sync 2>&1) || sync_exit=$?

    if [ $sync_exit -ne 0 ]; then
        log_error "Periodic sync failed"
        echo "$sync_output" | sed 's/^/  [sync] /'
        return
    fi

    # Parse sync results - only show output if something happened
    local merged_count comments_count
    merged_count=$(echo "$sync_output" | sed -n 's/.*Merged PRs updated: \([0-9]*\).*/\1/p' | head -1)
    comments_count=$(echo "$sync_output" | sed -n 's/.*Tasks with new comments: \([0-9]*\).*/\1/p' | head -1)
    merged_count=${merged_count:-0}
    comments_count=${comments_count:-0}

    if [ "$comments_count" -gt 0 ]; then
        log "PR sync: $comments_count task(s) with new comments"
        echo "$sync_output" | sed 's/^/  [sync] /'

        # Check for tasks needing fixes
        local tasks_needing_fix="$RALPH_DIR/.tasks-needing-fix.txt"
        if [ -s "$tasks_needing_fix" ]; then
            log "Tasks need comment fixes - will spawn fix workers"
        fi
    fi
}

# Pre-worker checks before spawning a new worker
# Returns 0 if safe to proceed, 1 if conflicts detected
pre_worker_checks() {
    # Pull latest changes from main with retry
    log "Pulling latest changes from origin/main..."

    local pull_output
    local max_attempts=3
    local delays=(2 4)

    for ((attempt=1; attempt<=max_attempts; attempt++)); do
        if pull_output=$(git pull --ff-only origin main 2>&1); then
            break
        fi

        # Immediately fail on conflicts (non-transient)
        if echo "$pull_output" | grep -qi "CONFLICT"; then
            log_error "Git pull conflict detected: $pull_output"
            log_error "Cannot spawn new workers with unresolved conflicts"
            return 1
        fi

        # On last attempt, give up
        if [ $attempt -eq $max_attempts ]; then
            log_error "Git pull failed after $max_attempts attempts: $pull_output"
            return 1
        fi

        # Transient error - retry with backoff
        local delay=${delays[$((attempt-1))]}
        log "Git pull attempt $attempt failed (transient), retrying in ${delay}s..."
        sleep "$delay"
    done

    # Check for conflicts with active worktrees
    local workers_dir="$RALPH_DIR/workers"
    if [ -d "$workers_dir" ]; then
        for worker_dir in "$workers_dir"/worker-*; do
            [ -d "$worker_dir/workspace" ] || continue

            local workspace="$worker_dir/workspace"
            if [ -d "$workspace/.git" ] || [ -f "$workspace/.git" ]; then
                # Check if worktree has conflicts with main
                if git -C "$workspace" diff --name-only origin/main 2>/dev/null | \
                   xargs -I {} git -C "$workspace" diff --check origin/main -- {} 2>&1 | \
                   grep -q "conflict"; then
                    log_error "Conflict detected in $(basename "$worker_dir")"
                    return 1
                fi
            fi
        done
    fi

    return 0
}

# Check for workers needing fixes and spawn fix workers
check_and_spawn_fixes() {
    local tasks_needing_fix="$RALPH_DIR/.tasks-needing-fix.txt"

    if [ ! -s "$tasks_needing_fix" ]; then
        return 0
    fi

    # Check fix worker capacity
    if [ ${#active_fix_workers[@]} -ge "$FIX_WORKER_LIMIT" ]; then
        log "Fix worker limit reached ($FIX_WORKER_LIMIT) - deferring new fixes"
        return 0
    fi

    log "Checking for tasks needing PR comment fixes..."

    while read -r task_id; do
        [ -z "$task_id" ] && continue

        # Re-check capacity inside loop
        if [ ${#active_fix_workers[@]} -ge "$FIX_WORKER_LIMIT" ]; then
            break
        fi

        local worker_dir
        worker_dir=$(find_worker_by_task_id "$RALPH_DIR" "$task_id" 2>/dev/null)

        if [ -z "$worker_dir" ] || [ ! -d "$worker_dir" ]; then
            continue
        fi

        # Check for needs_fix state (use git-state.json)
        if git_state_is "$worker_dir" "needs_fix"; then
            # Guard: skip if agent is already running for this worker
            if [ -f "$worker_dir/agent.pid" ]; then
                local existing_pid
                existing_pid=$(cat "$worker_dir/agent.pid")
                if kill -0 "$existing_pid" 2>/dev/null; then
                    log "Fix agent already running for $task_id (PID: $existing_pid) - skipping"
                    continue
                fi
            fi

            # Transition state to fixing
            git_state_set "$worker_dir" "fixing" "wiggum-run.check_and_spawn_fixes" "Fix worker spawned"

            log "Spawning fix worker for $task_id..."

            # Call wiggum-review task fix synchronously (it returns immediately after async launch)
            (
                cd "$PROJECT_DIR" || exit 1
                "$WIGGUM_HOME/bin/wiggum-review" task "$task_id" fix 2>&1 | \
                    sed "s/^/  [fix-$task_id] /"
            )

            # Read the agent PID from the worker directory
            if [ -f "$worker_dir/agent.pid" ]; then
                local agent_pid
                agent_pid=$(cat "$worker_dir/agent.pid")
                active_fix_workers[$agent_pid]="$task_id|$(date +%s)"
                log "Fix worker spawned for $task_id (PID: $agent_pid)"
            else
                log "Warning: Fix agent for $task_id did not produce agent.pid"
            fi
        fi
    done < "$tasks_needing_fix"

    # Clear the tasks needing fix file after processing
    : > "$tasks_needing_fix"
}

# Create workspaces for orphaned PRs (PRs with comments but no local workspace)
# Then queue them for fix processing
create_orphan_pr_workspaces() {
    local orphan_file="$RALPH_DIR/.prs-needing-workspace.jsonl"

    if [ ! -s "$orphan_file" ]; then
        return 0
    fi

    log "Processing orphaned PRs needing workspace creation..."

    local processed=()
    while IFS= read -r line; do
        [ -z "$line" ] && continue

        local task_id pr_number branch
        task_id=$(echo "$line" | jq -r '.task_id')
        pr_number=$(echo "$line" | jq -r '.pr_number')
        branch=$(echo "$line" | jq -r '.branch')

        if [ -z "$task_id" ] || [ "$task_id" = "null" ]; then
            continue
        fi

        # Check if workspace already exists now (might have been created elsewhere)
        local existing_worker
        existing_worker=$(find_worker_by_task_id "$RALPH_DIR" "$task_id" 2>/dev/null)
        if [ -n "$existing_worker" ] && [ -d "$existing_worker/workspace" ]; then
            log "  $task_id: workspace already exists, skipping"
            processed+=("$task_id")
            continue
        fi

        # Create worker directory
        local timestamp worker_id worker_dir
        timestamp=$(date +%s)
        worker_id="worker-${task_id}-fix-${timestamp}"
        worker_dir="$RALPH_DIR/workers/$worker_id"

        mkdir -p "$worker_dir"
        log "  $task_id: Creating workspace from branch $branch"

        # Create worktree from PR branch
        if ! setup_worktree_from_branch "$PROJECT_DIR" "$worker_dir" "$branch"; then
            log_error "  $task_id: Failed to create workspace from branch $branch"
            rm -rf "$worker_dir"
            continue
        fi

        # Record branch and PR info
        echo "$branch" > "$worker_dir/branch.txt"
        git_state_set_pr "$worker_dir" "$pr_number"

        # Sync comments from review directory if they exist
        local review_comments="$RALPH_DIR/review/${task_id}-comments.json"
        if [ -f "$review_comments" ]; then
            cp "$review_comments" "$worker_dir/${task_id}-comments.json"
        fi

        # Also fetch fresh comments
        "$WIGGUM_HOME/bin/wiggum-review" task "$task_id" sync 2>/dev/null || true

        # Queue for fix processing
        echo "$task_id" >> "$RALPH_DIR/.tasks-needing-fix.txt"
        git_state_set "$worker_dir" "needs_fix" "wiggum-run.create_orphan_pr_workspaces" "Workspace created from PR branch"

        log "  $task_id: Workspace created, queued for fix"
        processed+=("$task_id")
    done < "$orphan_file"

    # Remove processed entries from orphan file
    if [ ${#processed[@]} -gt 0 ]; then
        local temp_file
        temp_file=$(mktemp)
        while IFS= read -r line; do
            local task_id
            task_id=$(echo "$line" | jq -r '.task_id')
            local skip=false
            for p in "${processed[@]}"; do
                if [ "$task_id" = "$p" ]; then
                    skip=true
                    break
                fi
            done
            if [ "$skip" = false ]; then
                echo "$line" >> "$temp_file"
            fi
        done < "$orphan_file"
        mv "$temp_file" "$orphan_file"
    fi
}

# Handle fix worker completion - verify push and transition state for merge
# Args: worker_dir, task_id
handle_fix_completion() {
    local worker_dir="$1"
    local task_id="$2"

    # Read the agent result to check push status
    local result_file="$worker_dir/agent-result.json"
    if [ ! -f "$result_file" ]; then
        log_warn "No agent-result.json for $task_id - cannot verify fix completion"
        return 1
    fi

    local gate_result push_succeeded
    gate_result=$(jq -r '.status // "FAIL"' "$result_file" 2>/dev/null)
    push_succeeded=$(jq -r '.outputs.push_succeeded // false' "$result_file" 2>/dev/null)

    if [ "$gate_result" = "PASS" ] && [ "$push_succeeded" = "true" ]; then
        git_state_set "$worker_dir" "fix_completed" "wiggum-run.handle_fix_completion" "Push verified"
        git_state_set "$worker_dir" "needs_merge" "wiggum-run.handle_fix_completion" "Ready for merge attempt"
        log "Fix completed for $task_id - ready for merge"
        return 0
    elif [ "$gate_result" = "PASS" ]; then
        # Fix succeeded but push didn't - still mark as completed
        git_state_set "$worker_dir" "fix_completed" "wiggum-run.handle_fix_completion" "Fix passed but push failed"
        log_warn "Fix completed for $task_id but push failed"
        return 0
    else
        git_state_set "$worker_dir" "failed" "wiggum-run.handle_fix_completion" "Fix agent returned: $gate_result"
        log_error "Fix failed for $task_id (result: $gate_result)"
        return 1
    fi
}

# Attempt to merge a PR for a worker
# Args: worker_dir, task_id
# Returns: 0 on success, 1 on conflict (needs resolver), 2 on other failure
attempt_pr_merge() {
    local worker_dir="$1"
    local task_id="$2"

    local pr_number
    pr_number=$(git_state_get_pr "$worker_dir")

    if [ "$pr_number" = "null" ] || [ -z "$pr_number" ]; then
        # Try to find PR number from branch
        local branch_file="$worker_dir/branch.txt"
        if [ -f "$branch_file" ]; then
            local branch
            branch=$(cat "$branch_file")
            pr_number=$(gh pr list --head "$branch" --state open --json number -q '.[0].number' 2>/dev/null || true)
            if [ -n "$pr_number" ]; then
                git_state_set_pr "$worker_dir" "$pr_number"
            fi
        fi
    fi

    if [ -z "$pr_number" ] || [ "$pr_number" = "null" ]; then
        log_warn "No PR number found for $task_id - cannot attempt merge"
        return 2
    fi

    git_state_set "$worker_dir" "merging" "wiggum-run.attempt_pr_merge" "Attempting merge of PR #$pr_number"
    git_state_inc_merge_attempts "$worker_dir"

    local merge_attempts
    merge_attempts=$(git_state_get_merge_attempts "$worker_dir")
    log "Attempting merge for $task_id PR #$pr_number (attempt $merge_attempts/$MAX_MERGE_ATTEMPTS)"

    local merge_output merge_exit=0
    merge_output=$(gh pr merge "$pr_number" --merge --delete-branch 2>&1) || merge_exit=$?

    if [ $merge_exit -eq 0 ]; then
        git_state_set "$worker_dir" "merged" "wiggum-run.attempt_pr_merge" "PR #$pr_number merged successfully"
        log "PR #$pr_number merged successfully for $task_id"

        # Update kanban status to complete
        if [ -f "$RALPH_DIR/kanban.md" ]; then
            update_kanban_status "$RALPH_DIR/kanban.md" "$task_id" "x"
        fi
        return 0
    fi

    # Check if failure is due to merge conflict
    if echo "$merge_output" | grep -qiE "(conflict|cannot be merged|out of date)"; then
        git_state_set_error "$worker_dir" "Merge conflict: $merge_output"
        git_state_set "$worker_dir" "merge_conflict" "wiggum-run.attempt_pr_merge" "Merge failed due to conflict"

        if [ "$merge_attempts" -lt "$MAX_MERGE_ATTEMPTS" ]; then
            git_state_set "$worker_dir" "needs_resolve" "wiggum-run.attempt_pr_merge" "Conflict resolver required"
            log "Merge conflict for $task_id - will spawn resolver"
            return 1
        else
            git_state_set "$worker_dir" "failed" "wiggum-run.attempt_pr_merge" "Max merge attempts ($MAX_MERGE_ATTEMPTS) exceeded"
            log_error "Max merge attempts exceeded for $task_id"
            return 2
        fi
    fi

    # Other merge failure
    git_state_set_error "$worker_dir" "Merge failed: $merge_output"
    git_state_set "$worker_dir" "failed" "wiggum-run.attempt_pr_merge" "Merge failed: ${merge_output:0:100}"
    log_error "Merge failed for $task_id: $merge_output"
    return 2
}

# Check for workers needing conflict resolution and spawn resolver workers
check_and_spawn_resolvers() {
    # Use same limit as fix workers (shared pool for priority workers)
    local total_priority_workers=$(( ${#active_fix_workers[@]} + ${#active_resolve_workers[@]} ))
    if [ "$total_priority_workers" -ge "$FIX_WORKER_LIMIT" ]; then
        return 0
    fi

    [ -d "$RALPH_DIR/workers" ] || return 0

    for worker_dir in "$RALPH_DIR/workers"/worker-*; do
        [ -d "$worker_dir" ] || continue

        # Re-check capacity
        total_priority_workers=$(( ${#active_fix_workers[@]} + ${#active_resolve_workers[@]} ))
        if [ "$total_priority_workers" -ge "$FIX_WORKER_LIMIT" ]; then
            break
        fi

        # Check for needs_resolve state
        git_state_is "$worker_dir" "needs_resolve" || continue

        local worker_id
        worker_id=$(basename "$worker_dir")
        local task_id
        task_id=$(get_task_id_from_worker "$worker_id")

        # Guard: skip if agent is already running
        if [ -f "$worker_dir/agent.pid" ]; then
            local existing_pid
            existing_pid=$(cat "$worker_dir/agent.pid")
            if kill -0 "$existing_pid" 2>/dev/null; then
                log "Resolver already running for $task_id (PID: $existing_pid) - skipping"
                continue
            fi
        fi

        # Transition state
        git_state_set "$worker_dir" "resolving" "wiggum-run.check_and_spawn_resolvers" "Resolver spawned"

        log "Spawning conflict resolver for $task_id..."

        # Call wiggum-review task resolve asynchronously
        (
            cd "$PROJECT_DIR" || exit 1
            "$WIGGUM_HOME/bin/wiggum-review" task "$task_id" resolve 2>&1 | \
                sed "s/^/  [resolve-$task_id] /"
        ) &
        local resolver_pid=$!

        active_resolve_workers[$resolver_pid]="$task_id|$(date +%s)"
        log "Resolver spawned for $task_id (PID: $resolver_pid)"
    done
}

# Handle resolver completion - check result and transition state
# Args: worker_dir, task_id
handle_resolve_completion() {
    local worker_dir="$1"
    local task_id="$2"

    # Check if conflicts are resolved
    local workspace="$worker_dir/workspace"
    if [ ! -d "$workspace" ]; then
        git_state_set "$worker_dir" "failed" "wiggum-run.handle_resolve_completion" "Workspace not found"
        return 1
    fi

    local remaining_conflicts
    remaining_conflicts=$(git -C "$workspace" diff --name-only --diff-filter=U 2>/dev/null || true)

    if [ -z "$remaining_conflicts" ]; then
        git_state_set "$worker_dir" "resolved" "wiggum-run.handle_resolve_completion" "All conflicts resolved"

        # Need to commit and push the resolution
        log "Conflicts resolved for $task_id - committing resolution..."

        (
            cd "$PROJECT_DIR" || exit 1
            "$WIGGUM_HOME/bin/wiggum-review" task "$task_id" commit 2>&1 | sed "s/^/  [commit-$task_id] /"
            "$WIGGUM_HOME/bin/wiggum-review" task "$task_id" push 2>&1 | sed "s/^/  [push-$task_id] /"
        )

        # Ready for another merge attempt
        git_state_set "$worker_dir" "needs_merge" "wiggum-run.handle_resolve_completion" "Ready for merge retry"
        return 0
    else
        local count
        count=$(echo "$remaining_conflicts" | wc -l)
        git_state_set "$worker_dir" "failed" "wiggum-run.handle_resolve_completion" "$count files still have conflicts"
        log_error "Resolver failed for $task_id - $count files still have conflicts"
        return 1
    fi
}

# Detect orphan workers (running PIDs not tracked in active_workers)
# Re-tracks them with a warning
detect_orphan_workers() {
    [ -d "$RALPH_DIR/workers" ] || return 0

    scan_output=$(scan_active_workers "$RALPH_DIR") || {
        scan_rc=$?
        if [ "$scan_rc" -eq 2 ]; then
            log_warn "Worker scan encountered lock contention, results may be incomplete"
        fi
    }
    while read -r worker_pid task_id _worker_id; do
        [ -n "$worker_pid" ] || continue
        # Check if this PID is already tracked
        if [ -z "${active_workers[$worker_pid]+x}" ]; then
            log "WARNING: Detected orphan worker for $task_id (PID: $worker_pid) - re-tracking"
            active_workers[$worker_pid]="$task_id"
        fi
    done <<< "$scan_output"
}

main() {
    # Parse run options
    while [[ $# -gt 0 ]]; do
        case "$1" in
            plan)
                export WIGGUM_PLAN_MODE=true
                shift
                ;;
            --max-workers)
                if [[ -z "${2:-}" ]] || [[ "${2:-}" =~ ^- ]]; then
                    echo "Error: --max-workers requires a number argument"
                    exit $EXIT_USAGE
                fi
                MAX_WORKERS="$2"
                shift 2
                ;;
            --max-iters)
                if [[ -z "${2:-}" ]] || [[ "${2:-}" =~ ^- ]]; then
                    echo "Error: --max-iters requires a number argument"
                    exit $EXIT_USAGE
                fi
                MAX_ITERATIONS="$2"
                shift 2
                ;;
            --max-turns)
                if [[ -z "${2:-}" ]] || [[ "${2:-}" =~ ^- ]]; then
                    echo "Error: --max-turns requires a number argument"
                    exit $EXIT_USAGE
                fi
                MAX_TURNS="$2"
                shift 2
                ;;
            --force)
                FORCE_LOCK=true
                shift
                ;;
            -h|--help)
                show_help
                exit $EXIT_OK
                ;;
            -*)
                echo "Unknown option: $1"
                echo ""
                show_help
                exit $EXIT_USAGE
                ;;
            *)
                echo "Unknown argument: $1"
                echo ""
                show_help
                exit $EXIT_USAGE
                ;;
        esac
    done

    # Initialize project if needed
    if [ ! -d "$RALPH_DIR" ]; then
        log_error ".ralph/ directory not found. Run 'wiggum init' first."
        exit $EXIT_RUN_NO_RALPH_DIR
    fi

    # Load rate limit configuration
    load_rate_limit_config

    # Initialize activity log
    activity_init "$PROJECT_DIR"

    # Ensure only one orchestrator runs at a time (not local - needed by trap handler)
    orchestrator_lock="$RALPH_DIR/.orchestrator.pid"

    # Check if another orchestrator is already running
    if [ -f "$orchestrator_lock" ]; then
        local existing_pid
        existing_pid=$(cat "$orchestrator_lock" 2>/dev/null)

        # Validate PID is a number
        if [[ "$existing_pid" =~ ^[0-9]+$ ]]; then
            # Check if that process is still running and is wiggum-run
            if kill -0 "$existing_pid" 2>/dev/null; then
                if ps -p "$existing_pid" -o args= 2>/dev/null | grep -q "wiggum-run"; then
                    if [ "$FORCE_LOCK" = true ]; then
                        log "WARNING: Overriding lock held by running orchestrator (PID: $existing_pid) due to --force"
                        rm -f "$orchestrator_lock"
                    else
                        log_error "Another wiggum-run orchestrator is already running (PID: $existing_pid)"
                        echo ""
                        echo "Only one orchestrator can run at a time to prevent conflicts."
                        echo "If you're sure no orchestrator is running, remove: $orchestrator_lock"
                        echo "Or use --force to override the lock."
                        exit $EXIT_RUN_ORCHESTRATOR_RUNNING
                    fi
                else
                    # PID exists but it's not wiggum-run (PID reused)
                    log "Cleaning stale orchestrator lock (PID reused)"
                    rm -f "$orchestrator_lock"
                fi
            else
                # Process no longer running
                log "Cleaning stale orchestrator lock"
                rm -f "$orchestrator_lock"
            fi
        else
            # Invalid PID in lock file
            log "Cleaning invalid orchestrator lock"
            rm -f "$orchestrator_lock"
        fi
    fi

    # Create orchestrator lock file
    echo "$$" > "$orchestrator_lock"
    log "Created orchestrator lock (PID: $$)"

    # Track shutdown state (not local - needed by trap handlers)
    _ORCH_SHUTDOWN_REQUESTED=false

    # Setup trap to cleanup lock file on exit
    cleanup_orchestrator() {
        if [ "${_ORCH_SHUTDOWN_REQUESTED:-false}" = false ]; then
            log "Cleaning up orchestrator lock"
            _ORCH_SHUTDOWN_REQUESTED=true
            rm -f "$orchestrator_lock"
        fi
    }
    trap cleanup_orchestrator EXIT

    # Handle INT and TERM signals - stop orchestration but leave workers running
    handle_shutdown_signal() {
        log ""
        log "Shutdown signal received - stopping orchestrator"
        log "Active workers will continue running to completion"
        log "Use 'wiggum status' to monitor worker progress"
        cleanup_orchestrator
        exit $EXIT_SIGINT
    }
    trap handle_shutdown_signal INT TERM

    if [ ! -f "$RALPH_DIR/kanban.md" ]; then
        log_error ".ralph/kanban.md not found. Create a kanban file first."
        exit $EXIT_RUN_NO_KANBAN
    fi

    # Validate kanban format before running
    log "Validating kanban.md format..."
    if ! "$WIGGUM_HOME/bin/wiggum-validate" --quiet; then
        log_error "Kanban validation failed. Run 'wiggum validate' to see details."
        exit $EXIT_RUN_VALIDATION_FAILED
    fi
    log "Kanban validation passed"

    # Check for self and circular dependencies
    log "Checking for dependency cycles..."
    local dep_errors
    declare -gA cyclic_tasks=()  # task_id -> error type (SELF or CYCLE)
    if dep_errors=$(detect_circular_dependencies "$RALPH_DIR/kanban.md"); then
        log "No dependency cycles detected"
    else
        # Parse errors and populate cyclic_tasks for skipping
        while IFS= read -r line; do
            if [[ "$line" =~ ^SELF:(.+)$ ]]; then
                local task_id="${BASH_REMATCH[1]}"
                cyclic_tasks[$task_id]="SELF"
                log_error "Self-dependency detected: $task_id depends on itself - will be skipped"
            elif [[ "$line" =~ ^CYCLE:(.+)$ ]]; then
                local cycle_members="${BASH_REMATCH[1]}"
                for task_id in $cycle_members; do
                    cyclic_tasks[$task_id]="CYCLE"
                done
                log_error "Circular dependency detected involving:$cycle_members - will be skipped"
            fi
        done <<< "$dep_errors"

        if [ ${#cyclic_tasks[@]} -gt 0 ]; then
            log_warn "Skipping ${#cyclic_tasks[@]} task(s) due to dependency errors"
        fi
    fi

    # Check for clean git status
    if [ -n "$(git status --porcelain 2>/dev/null)" ]; then
        log_error "Git working directory is not clean. Please commit or stash your changes before running."
        echo ""
        echo "Uncommitted changes detected:"
        git status --short
        exit $EXIT_RUN_GIT_DIRTY
    fi

    # Pre-flight checks: Ensure SSH keys are cached and gh is authenticated
    log "Running pre-flight checks..."

    # Extract hostname from git remote
    local git_remote
    git_remote=$(git remote get-url origin 2>/dev/null)
    if [ -n "$git_remote" ]; then
        # Extract hostname from SSH URLs (git@github.com:user/repo.git or ssh://git@github.com/user/repo.git)
        local git_host=""
        if [[ "$git_remote" =~ ^git@([^:]+): ]]; then
            git_host="${BASH_REMATCH[1]}"
        elif [[ "$git_remote" =~ ^ssh://git@([^/]+)/ ]]; then
            git_host="${BASH_REMATCH[1]}"
        fi

        if [ -n "$git_host" ]; then
            echo "  → Testing SSH connection to $git_host..."
            local ssh_output
            ssh_output=$(ssh -T "git@$git_host" 2>&1) || true
            echo "$ssh_output" | head -5
            if ! echo "$ssh_output" | grep -qi "successfully authenticated"; then
                log_error "SSH test failed. Please ensure your SSH keys are set up and the agent is running."
                echo ""
                echo "Try running: ssh -T git@$git_host"
                exit $EXIT_RUN_SSH_FAILED
            fi
            echo "  ✓ SSH connection successful"
        fi
    fi

    # Test GitHub CLI authentication
    echo "  → Checking gh auth status..."
    if gh auth status &>/dev/null; then
        echo "  ✓ GitHub CLI authenticated"
    else
        log_error "gh auth check failed. Please log in with: gh auth login"
        echo ""
        echo "Try running: gh auth status"
        exit $EXIT_RUN_GH_AUTH_FAILED
    fi

    echo ""

    # Check for failed tasks and reset them to pending for retry
    local failed_tasks
    failed_tasks=$(get_failed_tasks "$RALPH_DIR/kanban.md")
    if [ -n "$failed_tasks" ]; then
        log "Found failed tasks - resetting for retry:"
        for task_id in $failed_tasks; do
            echo "  → Retrying $task_id"
            if ! update_kanban_status "$RALPH_DIR/kanban.md" "$task_id" " "; then
                log_error "Failed to reset $task_id to pending"
            fi
        done
        echo ""
    fi

    local mode_desc="standard"
    if [ "${WIGGUM_PLAN_MODE:-false}" = "true" ]; then
        mode_desc="plan mode"
    fi
    log "Starting Chief Wiggum in $PROJECT_DIR ($mode_desc, max $MAX_WORKERS concurrent workers)"
    echo ""
    echo "Press Ctrl+C to stop and view 'wiggum status' for details"
    echo "=========================================="
    echo ""

    # Track active workers
    declare -A active_workers=()         # PID -> task_id mapping
    declare -A active_fix_workers=()     # PID -> "task_id|start_time"
    declare -A active_resolve_workers=() # PID -> "task_id|start_time"
    declare -A skip_tasks=()             # task_id -> consecutive failure count
    local all_pids=()

    # Restore active workers from existing worker directories (using shared library)
    if [ -d "$RALPH_DIR/workers" ]; then
        log "Scanning for active workers from previous runs..."
        scan_output=$(scan_active_workers "$RALPH_DIR") || {
            scan_rc=$?
            if [ "$scan_rc" -eq 2 ]; then
                log_warn "Worker scan encountered lock contention, results may be incomplete"
            fi
        }
        while read -r worker_pid task_id _worker_id; do
            [ -n "$worker_pid" ] || continue
            active_workers[$worker_pid]="$task_id"
            all_pids+=("$worker_pid")
            log "Restored tracking for $task_id (PID: $worker_pid)"
        done <<< "$scan_output"

        # Migrate legacy .needs-fix markers to git-state.json
        for worker_dir in "$RALPH_DIR/workers"/worker-*; do
            [ -d "$worker_dir" ] || continue
            if [ -f "$worker_dir/.needs-fix" ] && [ ! -f "$worker_dir/git-state.json" ]; then
                local migrated_task_id
                migrated_task_id=$(get_task_id_from_worker "$(basename "$worker_dir")")
                git_state_set "$worker_dir" "needs_fix" "wiggum-run.migration" "Migrated from .needs-fix marker"
                rm -f "$worker_dir/.needs-fix"
                log "Migrated legacy .needs-fix for $migrated_task_id to git-state.json"
            fi
        done
    fi

    local iteration=0
    local sync_counter=0
    local ready_since_file="$RALPH_DIR/.task-ready-since"
    # Initialize ready-since file if it doesn't exist
    touch "$ready_since_file"

    # Main orchestration loop
    while true; do
        ((++iteration))
        ((++sync_counter))

        # Run periodic sync every SYNC_INTERVAL iterations
        if [ $sync_counter -ge $SYNC_INTERVAL ]; then
            run_periodic_sync
            sync_counter=0

            # Update shared usage data periodically
            usage_tracker_write_shared "$RALPH_DIR" > /dev/null 2>&1 || true

            # Decay skip counts - give tasks another chance
            for skip_id in "${!skip_tasks[@]}"; do
                skip_tasks[$skip_id]=$(( ${skip_tasks[$skip_id]} - 1 ))
                if [ "${skip_tasks[$skip_id]}" -le 0 ]; then
                    unset "skip_tasks[$skip_id]"
                fi
            done

            # Create workspaces for orphaned PRs (PRs needing fixes but no local workspace)
            create_orphan_pr_workspaces

            # Check for and spawn fix workers after sync
            check_and_spawn_fixes
        fi

        # Get tasks ready to run (pending with satisfied dependencies, sorted by priority)
        # Includes: aging bonus, sibling WIP penalty, plan bonus, dependency bonus
        local ready_tasks
        ready_tasks=$(get_ready_tasks "$RALPH_DIR/kanban.md" "$ready_since_file" "$AGING_FACTOR" "$SIBLING_WIP_PENALTY" "$RALPH_DIR" "$PLAN_BONUS" "$DEP_BONUS_PER_TASK")

        # Track if scheduling events occurred (used for aging updates)
        local scheduling_event=false

        local blocked_tasks
        blocked_tasks=$(get_blocked_tasks "$RALPH_DIR/kanban.md")
        local all_pending
        all_pending=$(get_todo_tasks "$RALPH_DIR/kanban.md")

        # Clean up finished workers
        for pid in "${!active_workers[@]}"; do
            if ! kill -0 "$pid" 2>/dev/null; then
                activity_log "worker.completed" "" "${active_workers[$pid]}" "pid=$pid"
                log "Worker for ${active_workers[$pid]} finished (PID: $pid)"
                unset "active_workers[$pid]"
                scheduling_event=true  # Worker finished = scheduling opportunity
            fi
        done

        # Detect orphan workers not in our tracking
        detect_orphan_workers

        # Clean up finished/timed-out fix workers and handle completion workflow
        local now
        now=$(date +%s)
        for fix_pid in "${!active_fix_workers[@]}"; do
            local fix_info="${active_fix_workers[$fix_pid]}"
            local fix_task_id="${fix_info%%|*}"
            local fix_start="${fix_info##*|}"

            if ! kill -0 "$fix_pid" 2>/dev/null; then
                # Check agent-result.json for structured status
                local fix_worker_dir
                fix_worker_dir=$(find_worker_by_task_id "$RALPH_DIR" "$fix_task_id" 2>/dev/null)
                if [ -n "$fix_worker_dir" ]; then
                    # Handle fix completion - verify push and transition state
                    if handle_fix_completion "$fix_worker_dir" "$fix_task_id"; then
                        # Fix succeeded - attempt merge
                        if git_state_is "$fix_worker_dir" "needs_merge"; then
                            attempt_pr_merge "$fix_worker_dir" "$fix_task_id" || true
                        fi
                    fi
                else
                    log "Fix worker for $fix_task_id finished (PID: $fix_pid)"
                fi
                unset "active_fix_workers[$fix_pid]"
            elif [ $(( now - fix_start )) -ge "$FIX_WORKER_TIMEOUT" ]; then
                log "WARNING: Fix worker for $fix_task_id timed out after ${FIX_WORKER_TIMEOUT}s - killing (PID: $fix_pid)"
                kill "$fix_pid" 2>/dev/null || true
                if [ -n "$fix_worker_dir" ]; then
                    git_state_set "$fix_worker_dir" "failed" "wiggum-run" "Fix worker timed out after ${FIX_WORKER_TIMEOUT}s"
                fi
                unset "active_fix_workers[$fix_pid]"
            fi
        done

        # Clean up finished/timed-out resolve workers
        for resolve_pid in "${!active_resolve_workers[@]}"; do
            local resolve_info="${active_resolve_workers[$resolve_pid]}"
            local resolve_task_id="${resolve_info%%|*}"
            local resolve_start="${resolve_info##*|}"

            if ! kill -0 "$resolve_pid" 2>/dev/null; then
                local resolve_worker_dir
                resolve_worker_dir=$(find_worker_by_task_id "$RALPH_DIR" "$resolve_task_id" 2>/dev/null)
                if [ -n "$resolve_worker_dir" ]; then
                    # Handle resolve completion
                    if handle_resolve_completion "$resolve_worker_dir" "$resolve_task_id"; then
                        # Resolution succeeded - attempt merge
                        if git_state_is "$resolve_worker_dir" "needs_merge"; then
                            attempt_pr_merge "$resolve_worker_dir" "$resolve_task_id" || true
                        fi
                    fi
                else
                    log "Resolve worker for $resolve_task_id finished (PID: $resolve_pid)"
                fi
                unset "active_resolve_workers[$resolve_pid]"
            elif [ $(( now - resolve_start )) -ge "$RESOLVE_WORKER_TIMEOUT" ]; then
                log "WARNING: Resolve worker for $resolve_task_id timed out after ${RESOLVE_WORKER_TIMEOUT}s - killing (PID: $resolve_pid)"
                kill "$resolve_pid" 2>/dev/null || true
                if [ -n "$resolve_worker_dir" ]; then
                    git_state_set "$resolve_worker_dir" "failed" "wiggum-run" "Resolve worker timed out after ${RESOLVE_WORKER_TIMEOUT}s"
                fi
                unset "active_resolve_workers[$resolve_pid]"
            fi
        done

        # Check for workers needing conflict resolution and spawn resolvers
        check_and_spawn_resolvers

        # Check if we're done (no pending tasks and no active workers)
        if [ -z "$all_pending" ] && [ ${#active_workers[@]} -eq 0 ]; then
            log "All tasks completed!"
            break
        fi

        # Check rate limit before spawning
        if rate_limit_check "$RALPH_DIR"; then
            local cycle_prompts
            cycle_prompts=$(jq -r '.current_5h_cycle.total_prompts // 0' "$RALPH_DIR/claude-usage.json" 2>/dev/null)
            log "Rate limit threshold reached ($cycle_prompts >= $WIGGUM_RATE_LIMIT_THRESHOLD prompts in 5h cycle)"
            activity_log "rate_limit.detected" "" "" "prompts=$cycle_prompts threshold=$WIGGUM_RATE_LIMIT_THRESHOLD"
            rate_limit_wait_for_cycle_reset
            activity_log "rate_limit.resumed" "" ""
            usage_tracker_write_shared "$RALPH_DIR" > /dev/null 2>&1 || true
            continue  # Re-check state after reset
        fi

        # Spawn workers for ready tasks (up to MAX_WORKERS limit)
        for task_id in $ready_tasks; do
            # Check if we're at max capacity
            if [ ${#active_workers[@]} -ge "$MAX_WORKERS" ]; then
                break
            fi

            # Skip tasks with dependency cycles (self-dependency or circular)
            if [ -n "${cyclic_tasks[$task_id]+x}" ]; then
                continue
            fi

            # Skip tasks that have recently failed kanban updates
            if [ -n "${skip_tasks[$task_id]+x}" ] && [ "${skip_tasks[$task_id]}" -gt 0 ]; then
                if [ "${skip_tasks[$task_id]}" -ge "$MAX_SKIP_RETRIES" ]; then
                    log_error "Task $task_id permanently skipped after $MAX_SKIP_RETRIES consecutive kanban failures"
                fi
                continue
            fi

            # Skip if file conflict with active worker
            if has_file_conflict "$RALPH_DIR" "$task_id" active_workers; then
                local conflicts
                conflicts=$(get_conflicting_files "$RALPH_DIR" "$task_id" active_workers | tr '\n' ',' | sed 's/,$//')
                log "Deferring $task_id - file conflict: $conflicts"
                continue
            fi

            # Run pre-worker checks (git pull, conflict detection)
            if ! pre_worker_checks; then
                log_error "Pre-worker checks failed for $task_id - skipping this task"
                continue
            fi

            # Get task priority for logging
            local task_priority
            task_priority=$(get_task_priority "$RALPH_DIR/kanban.md" "$task_id")

            # Mark task as in-progress in kanban
            log "Assigning $task_id (Priority: ${task_priority:-MEDIUM}) to new worker"
            if ! update_kanban_status "$RALPH_DIR/kanban.md" "$task_id" "="; then
                log_error "Failed to mark $task_id as in-progress"
                skip_tasks[$task_id]=$(( ${skip_tasks[$task_id]:-0} + 1 ))
                log "Task $task_id skip count: ${skip_tasks[$task_id]}/$MAX_SKIP_RETRIES"
                continue
            fi

            # Spawn worker (wiggum-start handles backgrounding)
            if ! spawn_worker "$task_id"; then
                log_error "Failed to spawn worker for $task_id"
                update_kanban_status "$RALPH_DIR/kanban.md" "$task_id" "*"
                continue
            fi

            active_workers[$SPAWNED_WORKER_PID]="$task_id"
            all_pids+=("$SPAWNED_WORKER_PID")
            scheduling_event=true  # Task spawned = other ready tasks were passed over

            # Remove from ready-since tracking (task is no longer waiting)
            if [ -f "$ready_since_file" ]; then
                sed_inplace "/^${task_id}|/d" "$ready_since_file"
            fi

            # Log task assignment to audit log
            audit_log_task_assigned "$task_id" "$SPAWNED_WORKER_ID" "$SPAWNED_WORKER_PID"

            log "Spawned worker $SPAWNED_WORKER_ID for $task_id (PID: $SPAWNED_WORKER_PID)"
        done

        # Update ready-since tracking only when scheduling events occurred
        # (task spawned or worker finished = tasks still waiting were passed over)
        if [ "$scheduling_event" = true ]; then
            local new_ready_since
            new_ready_since=$(mktemp)
            # Re-fetch ready tasks to get current state after spawning
            local current_ready
            current_ready=$(get_ready_tasks "$RALPH_DIR/kanban.md" "$ready_since_file" "$AGING_FACTOR" "$SIBLING_WIP_PENALTY" "$RALPH_DIR" "$PLAN_BONUS" "$DEP_BONUS_PER_TASK")
            for task_id in $current_ready; do
                local prev_count
                prev_count=$(awk -F'|' -v t="$task_id" '$1 == t { print $2 }' "$ready_since_file" 2>/dev/null)
                prev_count=${prev_count:-0}
                echo "$task_id|$(( prev_count + 1 ))" >> "$new_ready_since"
            done
            mv "$new_ready_since" "$ready_since_file"
        fi

        # Show status only when scheduling events occur
        if [ "$scheduling_event" = true ]; then
            echo ""
            echo "=== Status Update (iteration $iteration) ==="
            echo "Active workers: ${#active_workers[@]}/$MAX_WORKERS"

            # Show which tasks are being worked on
            if [ ${#active_workers[@]} -gt 0 ]; then
                echo "In Progress:"
                for pid in "${!active_workers[@]}"; do
                    echo "  - ${active_workers[$pid]} (PID: $pid)"
                done
            fi

            # Show active fix workers
            if [ ${#active_fix_workers[@]} -gt 0 ]; then
                echo "Fix Workers:"
                for fix_pid in "${!active_fix_workers[@]}"; do
                    local fix_info="${active_fix_workers[$fix_pid]}"
                    local fix_task_id="${fix_info%%|*}"
                    local fix_start="${fix_info##*|}"
                    local fix_elapsed=$(( $(date +%s) - fix_start ))
                    echo "  - $fix_task_id (PID: $fix_pid, ${fix_elapsed}s elapsed)"
                done
            fi

            # Show active resolve workers
            if [ ${#active_resolve_workers[@]} -gt 0 ]; then
                echo "Resolve Workers:"
                for resolve_pid in "${!active_resolve_workers[@]}"; do
                    local resolve_info="${active_resolve_workers[$resolve_pid]}"
                    local resolve_task_id="${resolve_info%%|*}"
                    local resolve_start="${resolve_info##*|}"
                    local resolve_elapsed=$(( $(date +%s) - resolve_start ))
                    echo "  - $resolve_task_id (PID: $resolve_pid, ${resolve_elapsed}s elapsed)"
                done
            fi

            # Show blocked tasks waiting on dependencies
            if [ -n "$blocked_tasks" ]; then
                echo "Blocked (waiting on dependencies):"
                for task_id in $blocked_tasks; do
                    local waiting_on
                    waiting_on=$(get_unsatisfied_dependencies "$RALPH_DIR/kanban.md" "$task_id" | tr '\n' ',' | sed 's/,$//')
                    echo "  - $task_id (waiting on: $waiting_on)"
                done
            fi

            # Show tasks skipped due to dependency cycles
            if [ ${#cyclic_tasks[@]} -gt 0 ]; then
                echo "Skipped (dependency cycle):"
                for task_id in "${!cyclic_tasks[@]}"; do
                    local error_type="${cyclic_tasks[$task_id]}"
                    if [ "$error_type" = "SELF" ]; then
                        echo "  - $task_id (self-dependency)"
                    else
                        echo "  - $task_id (circular dependency)"
                    fi
                done
            fi

            # Show tasks deferred due to file conflicts
            local deferred_conflicts=()
            for task_id in $ready_tasks; do
                if has_file_conflict "$RALPH_DIR" "$task_id" active_workers; then
                    deferred_conflicts+=("$task_id")
                fi
            done
            if [ ${#deferred_conflicts[@]} -gt 0 ]; then
                echo "Deferred (file conflict):"
                for task_id in "${deferred_conflicts[@]}"; do
                    local conflicting_tasks
                    conflicting_tasks=$(get_conflicting_tasks "$RALPH_DIR" "$task_id" active_workers | tr '\n' ',' | sed 's/,$//')
                    echo "  - $task_id (conflicts with: $conflicting_tasks)"
                done
            fi

            # Show top 7 ready tasks with priority scores (excluding in-progress and deferred)
            local ready_count
            ready_count=$(echo "$ready_tasks" | grep -c . 2>/dev/null || true)
            ready_count=${ready_count:-0}
            # Subtract in-progress and deferred tasks from count
            ready_count=$((ready_count - ${#active_workers[@]} - ${#deferred_conflicts[@]}))
            if [ "$ready_count" -gt 0 ]; then
                echo "Ready ($ready_count tasks, top 7 by priority):"
                # Get priority scores for display
                local all_metadata
                all_metadata=$(get_all_tasks_with_metadata "$RALPH_DIR/kanban.md")
                local display_count=0
                for task_id in $ready_tasks; do
                    [ "$display_count" -ge 7 ] && break
                    # Skip in-progress tasks
                    local is_active=false
                    for pid in "${!active_workers[@]}"; do
                        if [ "$task_id" = "${active_workers[$pid]}" ]; then
                            is_active=true
                            break
                        fi
                    done
                    [ "$is_active" = true ] && continue

                    # Skip deferred tasks
                    local is_deferred=false
                    for deferred in "${deferred_conflicts[@]}"; do
                        if [ "$task_id" = "$deferred" ]; then
                            is_deferred=true
                            break
                        fi
                    done
                    [ "$is_deferred" = true ] && continue

                    local priority iters_waiting effective_pri
                    priority=$(echo "$all_metadata" | awk -F'|' -v t="$task_id" '$1 == t { print $3 }')
                    iters_waiting=$(awk -F'|' -v t="$task_id" '$1 == t { print $2 }' "$ready_since_file" 2>/dev/null)
                    iters_waiting=${iters_waiting:-0}
                    effective_pri=$(get_effective_priority "$priority" "$iters_waiting" "$AGING_FACTOR")
                    # Apply plan bonus
                    if task_has_plan "$RALPH_DIR" "$task_id"; then
                        effective_pri=$((effective_pri - PLAN_BONUS))
                    fi
                    # Apply dep bonus
                    local dep_depth
                    dep_depth=$(get_dependency_depth "$RALPH_DIR/kanban.md" "$task_id")
                    effective_pri=$((effective_pri - dep_depth * DEP_BONUS_PER_TASK))
                    [[ "$effective_pri" -lt 0 ]] && effective_pri=0 || true
                    echo "  - $task_id (score: $effective_pri)"
                    ((++display_count))
                done
            fi

            # Show recent errors only (not info)
            if [ -f "$RALPH_DIR/logs/workers.log" ]; then
                local recent_errors
                recent_errors=$(grep -i "ERROR\|WARN" "$RALPH_DIR/logs/workers.log" 2>/dev/null | tail -n 5 || true)
                if [ -n "$recent_errors" ]; then
                    echo ""
                    echo "Recent errors:"
                    echo "$recent_errors" | sed 's/^/  /'
                fi
            fi
            echo "=========================================="
        fi

        # Wait a bit before checking again
        sleep 5
    done

    echo ""
    echo "=========================================="
    log "Chief Wiggum finished - all tasks complete!"
    echo ""

    # Show final summary
    local completed_count
    completed_count=$(grep -c '^\- \[x\]' "$RALPH_DIR/kanban.md" 2>/dev/null || echo "0")
    echo "Summary:"
    echo "  - Total tasks completed: $completed_count"
    echo "  - Changelog: .ralph/changelog.md"
    echo ""
    echo "Next steps:"
    echo "  - Review completed work: wiggum review list"
    echo "  - Merge PRs: wiggum review merge-all"
    echo "  - Clean up: wiggum clean"
    echo ""
}

main "$@"
